# NLP-Strategies
This repository contains two Jupyter Notebooks that provides a comprehensive discussion on various Natural Language Processing (NLP) strategies and the critical issue of train-test contamination. The notebook is designed to serve as an educational resource. [Link to the dataset](https://www.kaggle.com/datasets/itachi9604/disease-symptom-description-dataset?select=dataset.csv)

## Contents:
### [Part 1](https://www.kaggle.com/code/mghobashy/100-accuracy-model-using-one-hot-encoding):
TThis notebook illustrates a particular scenario where one-hot encoding can enhance model performance. Use the provided code and examples as a starting point for exploring feature encoding techniques and their impact on model performance.
* Dataset Description and Preparation
* Label Encoding the data
* Model Training
* Model Evaluation
* One-Hot Encoding the data
* Model Training
* Model Evaluation

### [Part 2](https://www.kaggle.com/code/mghobashy/train-test-contamination):
This repository provides a detailed discussion on the issue of train-test contamination in machine learning and how we can navigate around it to enhance the model preformance.
* Data Preparation
* LSTM Model Building and Evalutation
* Causes and Consequences of Train-Test Contamination
* K-Means Model using Keras Text Vectorizer and Embeddings
* Model Evalutaion
* K-Means Model using TF-IDF
* Model Evalutaion
* Models comparison
* Conclusion

## Contributing
Contributions are welcome! If you have any suggestions or improvements, please create a pull request or open an issue.

## Acknowledgments
Special thanks to [@ahmedshafiq12](https://github.com/ahmedshafiq12) for his valuable contributions and insights.

## Contact
For any questions or inquiries, please contact mhghobashy@gmail.com
